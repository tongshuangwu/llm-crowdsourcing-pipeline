{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06797264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85109c",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "This part will help you get access to OpenAI API and run your first completion.\n",
    "- For more information about model size and pricing, see [this page](https://openai.com/api/pricing/).\n",
    "- For a complete explanation of models, please see [the model overview](https://platform.openai.com/docs/models/overview).\n",
    "- For a detailed API walkthrough (with examples), see [this documentation page](https://beta.openai.com/docs/api-reference/completions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44e2362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6t5LX0pEP5fUsU2E3cTg0rsY6OhJh at 0x7fea515ad9b0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" of your ability to read the signs\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1678586611,\n",
       "  \"id\": \"cmpl-6t5LX0pEP5fUsU2E3cTg0rsY6OhJh\",\n",
       "  \"model\": \"ada\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 7,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 12\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get openAI access and see its model list\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "with open(\"./credential.json\", \"r\") as f:\n",
    "    credential = json.load(f)[\"openai\"]\n",
    "openai.api_key = credential\n",
    "\n",
    "# Test to see if you've got the access successfuly using the cheapest model.\n",
    "completion = openai.Completion.create(\n",
    "  model=\"ada\",\n",
    "  prompt=\"Say this is a test\",\n",
    "  max_tokens=7,\n",
    "  temperature=0\n",
    ")\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4291a43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' of your ability to read the signs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you got the completion successfully, you should be able to access the generated text through this line:\n",
    "completion[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04851c0c",
   "metadata": {},
   "source": [
    "# Writeup 0: Task and Strategy Description\n",
    "\n",
    "Here, you should describe what task you are working on, and what workflow/pipeline you intend to replicate (from which crowdsourcing paper). As a reminder, you should [pick a crowdsourcing paper here](https://docs.google.com/spreadsheets/d/1nIoU04CulTH128-r6rtykhuqNdd37UJXShw2J19IEdE/edit?usp=sharing). The spreadsheet also points to example tasks in the crowdsourcing papers; However, you DON'T have to stick to the paper-provided input/output. Please feel free to come up with your own tasks as long as they seem suitable for the paper/pipeline you are replicating.\n",
    "\n",
    "\n",
    "**EDIT THIS PART TO PROVIDE AN OVERVIEW OF YOUR ATTEMPTS**.\n",
    "\n",
    "- **Task Description**: Create three metaphors for a given concept, so that we can explain the different aspects of crowdsourcing in a poetic way. A metaphor may look like:\n",
    "\n",
    "    > In crowdsourcing, people are like bees; they work together to make honey.\n",
    "\n",
    "    With the concept being “crowdsourcing”, the simile being “bees”, and the similar aspect being “work together.”\n",
    "    \n",
    "    This task is from paper [AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts](https://arxiv.org/pdf/2110.01691.pdf), Case 0 in Appendix B.3.\n",
    "- **Example Input/output**: Write >=3 input-output pairs of your task. You should test your strategy on all the three examples.\n",
    "    ```\n",
    "    Input: Crowdsourcing\n",
    "    Output: \n",
    "    1. crowdsourcing is like a team sport in that it brings people to achieve one goal.\n",
    "    2. Crowdsourcing is like a vast, open-source library, with everyone contributing to the shelves of knowledge.\n",
    "    3. Crowdsourcing was like a quilt, with each individual contributing a patch of fabric to create a larger piece of art.\n",
    "\n",
    "    Input: Gratitude\n",
    "    Output:\n",
    "    1. gratitude is like a stream in that it’s a force that can carry you along.\n",
    "    2. Gratitude is like a generous river that overflows with blessings.\n",
    "    3. Gratitude is a feather in the cap of humility.\n",
    "\n",
    "    Input: loss\n",
    "    Output:\n",
    "    1. loss is like a wing in that it’s something you never wanted to lose, and it can take you away.\n",
    "    2. The loss was like a dark cloud of disappointment hovering over me.\n",
    "    3. Loss is a heavy burden, weighing down the heart like a funeral shroud.\n",
    "    ```\n",
    "- **Workflow prompting strategy**: The pipeline helps further specify an abstract query into more specific aspects. Given an input concept, we will\n",
    "    - First find three unique traits of the concept\n",
    "    - Ask the model to write a different metaphor for each trait.\n",
    "    \n",
    "    For example:\n",
    "    ```\n",
    "    INPUT: gratitude\n",
    "    Output: \n",
    "    TRAIT => OUTPUT: \n",
    "    Appreciation => Gratitude is a warm embrace, showing appreciation for all that is given.\n",
    "    Generosity => Gratitude is like a generous river that overflows with blessings.\n",
    "    ```\n",
    "- **Crowdsourcing paper**: [Towards Large-Scale Collaborative Planning: Answering High-Level Search Queries Using Human Computation](https://ojs.aaai.org/index.php/AAAI/article/view/8092) -- where the pipelining strategy comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe87f82",
   "metadata": {},
   "source": [
    "## Coding: Use this part to do your prompting.\n",
    "\n",
    "**Please use `text-davinci-003` when you generate your final model outputs.** `text-davinci-003` is effectively InstructGPT, and it can do any language task with better quality, longer output, and consistent instruction-following than other versions of GPT-3 ([as discussed in this page](https://platform.openai.com/docs/models/overview)). Using the latest model can give you a better idea on what these models are (not) capable of.\n",
    "\n",
    "Tips for prompting:\n",
    "- [OpenAI playground](https://beta.openai.com/playground) offers more interactive prompting experiments.\n",
    "- Read the [API documentation](https://beta.openai.com/docs/api-reference/completions?lang=python) to use the right parameters (e.g., `temperature`, `max_length`).\n",
    "- Read the [tutorial doc](https://beta.openai.com/docs/introduction) to get a general sense of GPT-3.\n",
    "- Read [OpenAI examples](https://beta.openai.com/examples) to get a sense of what GPT-3 can do.\n",
    "\n",
    "Tips for saving credits:\n",
    "\n",
    "- You can use a cheaper model for tweaking your prompts (see [pricing](https://openai.com/api/pricing/)) before generating the final responses using the most capable model `text-davinci-003`. However, be careful that sometimes a prompt that seems to not work for any other models may works for `text-davinci-003`.\n",
    "- [AI21](https://www.ai21.com/studio) provides a model similar to GPT-3 / API service similar to OpenAI, and it involves more free credits for you to try. If you choose to use this, remember to also get its API key and set up the credential.\n",
    "- Play with [ChatGPT](https://chat.openai.com/chat) which is a free and similarly capable model. It uses a dialog interface (vs. InstructGPT / `text-davinci-003` uses text completion interface), so naturally your way of interacting with the model may change a bit (e.g., you will ask questions there but use incomplete sentences here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be546aa",
   "metadata": {},
   "source": [
    "## Baseline prompting\n",
    "\n",
    "Use this section to do a one-step prompting for your selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59d2e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: crowdsourcing\n",
      "OUTPUT:  A quilt made of many pieces; 2. A hive of creativity; 3. A river of collective knowledge.\n",
      "\n",
      "INPUT: gratitude\n",
      "OUTPUT:  Gratitude is a garden of blessings. \n",
      "2. Gratitude is a river of joy. \n",
      "3. Gratitude is a sunbeam of appreciation.\n",
      "\n",
      "INPUT: loss\n",
      "OUTPUT:  His heart was an empty void. \n",
      "2. The grief was a heavy weight on his shoulders. \n",
      "3. He felt like he was walking through a dark tunnel.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "# If needed, change model=\"text-davinci-003\" to cheaper models!\n",
    "def baseline_prompt(concept, model=\"text-davinci-003\", max_tokens=100, temperature=0.7, top_p=1):\n",
    "    prompt = f\"\"\"The following is a list of three metaphors on '{concept}'.\n",
    "Concept: {concept}\n",
    "Metaphors: 1.\"\"\"\n",
    "    completion = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    output = completion[\"choices\"][0][\"text\"].split(\"4.\")[0]\n",
    "    print(f\"INPUT: {concept}\")\n",
    "    print(f\"OUTPUT: {output}\")\n",
    "    print()\n",
    "    \n",
    "baseline_prompt(\"crowdsourcing\")\n",
    "\n",
    "baseline_prompt(\"gratitude\")\n",
    "\n",
    "baseline_prompt(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f138dc",
   "metadata": {},
   "source": [
    "## Crowdsourcing-Pipeline-inspired prompting\n",
    "\n",
    "Use this section to your selected pipeline prompting for your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3665df0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: crowdsourcing\n",
      "TRAITS: \n",
      "['Open source collaboration', 'Leveraging collective intelligence', 'Collaborative problem-solving.']\n",
      "OUTPUT: \n",
      "Crowdsourcing is like a quilt, with each individual contributing a unique square to create a beautiful, shared piece of art.\n",
      "Crowdsourcing is like a hive of minds, collectively buzzing with creative solutions.\n",
      "Crowdsourcing is like a group of puzzle pieces coming together to form the perfect picture.\n",
      "\n",
      "INPUT: gratitude\n",
      "TRAITS: \n",
      "['Appreciation of kindness', 'Acknowledgement of help', 'Expression of thankfulness.']\n",
      "OUTPUT: \n",
      "Gratitude is like a rose, blossoming in appreciation of the kindness bestowed upon it.\n",
      "Gratitude is a bright beacon, illuminating the path of kindness and acknowledging the help of others.\n",
      "Gratitude is a sunflower, its vibrant petals reaching up to express its thankfulness.\n",
      "\n",
      "INPUT: loss\n",
      "TRAITS: \n",
      "['Desolation,', 'Disappointment,', 'Detachment.']\n",
      "OUTPUT: \n",
      "The world was a barren desert, devoid of hope and full of desolation.\n",
      "Disappointment settled over the room like a thick fog, obscuring the joy that had been there before.\n",
      "The grief of loss was like a balloon set free, slowly fading away in the distance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here.\n",
    "from functools import partial\n",
    "import re\n",
    "\n",
    "def pipeline_prompt(concept, model=\"text-davinci-003\", max_tokens=100, temperature=0.7, top_p=1):\n",
    "    prompt_concept_to_trait = f\"\"\"The following three phrases describes three different and unique traits of the given concept.\n",
    "Concept: {concept}\n",
    "Unique traits: 1.\"\"\"\n",
    "    completion = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt_concept_to_trait,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    traits = completion[\"choices\"][0][\"text\"].split(\"4.\")[0]\n",
    "    traits = [t.strip() for t in re.split(r'\\d+\\.', traits) if t.strip()]\n",
    "    \n",
    "    metaphors = []\n",
    "    for trait in traits:\n",
    "        prompt_trait_to_metaphor = f\"\"\"Given the concept and its unique trait, write a metaphor that conveys the corresponding trait.\n",
    "Concept: {concept}\n",
    "trait: {trait}\n",
    "metaphor:\"\"\"\n",
    "        completion = openai.Completion.create(\n",
    "            model=model,\n",
    "            prompt=prompt_trait_to_metaphor,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p\n",
    "        )\n",
    "        metaphors.append(completion[\"choices\"][0][\"text\"].strip())\n",
    "    metaphor = '\\n'.join(metaphors)\n",
    "    print(f\"INPUT: {concept}\")\n",
    "    print(f\"TRAITS: \\n{traits}\")\n",
    "    print(f\"OUTPUT: \\n{metaphor}\")\n",
    "    print()\n",
    "\n",
    "pipeline_prompt(\"crowdsourcing\")\n",
    "\n",
    "pipeline_prompt(\"gratitude\")\n",
    "\n",
    "pipeline_prompt(\"loss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1a375",
   "metadata": {},
   "source": [
    "# Writeup 1: Report & Reflection\n",
    "\n",
    "Fill in the following three sections by reflecting on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb3b42",
   "metadata": {},
   "source": [
    "## Report the result\n",
    "\n",
    "For all the inputs you tried, summarized the input, baseline output, pipeline output, which output you like and why. To answer \"why\", you should first think of some criteria you want to use for evaluating the output:\n",
    "\n",
    "### Important criteria:\n",
    "1. Diversity: The output should be diverse.\n",
    "2. Clarity: The output should be descriptive and clearly explains why a metaphor is used.\n",
    "\n",
    "### Inputs and outputs:\n",
    "\n",
    "- **Input**: loss\n",
    "- **Baseline output**: (diversity: 5/5, clarity: 1/5)\n",
    "    - His heart was an empty void. \n",
    "    - The grief was a heavy weight on his shoulders. \n",
    "    - He felt like he was walking through a dark tunnel.\n",
    "\n",
    "- **Pipeline output**: (diversity: 5/5, clarity: 1/5)\n",
    "    - The world was a barren desert, devoid of hope and full of desolation.\n",
    "    - Disappointment settled over the room like a thick fog, obscuring the joy that had been there before.\n",
    "    - The grief of loss was like a balloon set free, slowly fading away in the distance.\n",
    "\n",
    "- **Which output you like and why**:\n",
    "    I like the pipeline output, because it's much more clear why a simile is picked.\n",
    "\n",
    "--- \n",
    "\n",
    "- **Input**:\n",
    "- **Baseline output**:\n",
    "- **Pipeline output**:\n",
    "- **Which output you like and why**:\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f2ed6",
   "metadata": {},
   "source": [
    "## Reflect on prompting effectiveness\n",
    "\n",
    "Write some paragraphs to describe: Did you find the pipeline prompting workflow effective? Why or Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c87363",
   "metadata": {},
   "source": [
    "## Envision possible improvements\n",
    "\n",
    "Write some paragraphs to describe: What are some possible ways to further improve the pipeline or prompt design?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620c2ec",
   "metadata": {},
   "source": [
    "# Writeup 2 (Optional): InstructGPT vs. ChatGPT\n",
    "\n",
    "If you also tried to use the [ChatGPT](https://chat.openai.com/chat) interface to complete your task, you might have thoughts on these following two questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0166358",
   "metadata": {},
   "source": [
    "## Chat interface vs. complete-the-sentence interface\n",
    "Did your way of prompting change based on the interaction interface? What do you think are some pros and cons for the chat interface (you used in ChatGPT), and the complete-the-sentence interface (you used in this notebook)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df41d62",
   "metadata": {},
   "source": [
    "## Qualitative reflection on outputs\n",
    "Provide some examples of your ChatGPT output. Did you notice any differences?\n",
    "\n",
    "\n",
    "- **Input**:\n",
    "- **InstructGPT output**:\n",
    "- **ChatGPT output**:\n",
    "- **Which output you like and why**:\n",
    "\n",
    "---\n",
    "\n",
    "- **Input**:\n",
    "- **InstructGPT output**:\n",
    "- **ChatGPT output**:\n",
    "- **Which output you like and why**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb13ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
