{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06797264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the notebook\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85109c",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "\n",
    "This part will help you get access to OpenAI API and run your first completion.\n",
    "- For more information about model size and pricing, see [this page](https://openai.com/api/pricing/).\n",
    "- For a detailed API walkthrough (with examples), see [this documentation page](https://beta.openai.com/docs/api-reference/completions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8afb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6VBvNZ9r9yhK0in21fWSYqZpKtGaB at 0x7ff3d02c4dd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" of your ability to read the signs\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1672892025,\n",
       "  \"id\": \"cmpl-6VBvNZ9r9yhK0in21fWSYqZpKtGaB\",\n",
       "  \"model\": \"ada\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 7,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 12\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get openAI access and see its model list\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "with open(\"./credential.json\", \"r\") as f:\n",
    "    credential = json.load(f)[\"openai\"]\n",
    "openai.api_key = credential\n",
    "\n",
    "# Test to see if you've got the access successfuly using the cheapest model.\n",
    "completion = openai.Completion.create(\n",
    "  model=\"ada\",\n",
    "  prompt=\"Say this is a test\",\n",
    "  max_tokens=7,\n",
    "  temperature=0\n",
    ")\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8949a63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' of your ability to read the signs'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you got the completion successfully, you should be able to access the generated text through this line:\n",
    "completion[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a59871",
   "metadata": {},
   "source": [
    "# Writeup 0: Task and Strategy Description\n",
    "\n",
    "Here, you should describe what task you are working on, and what workflow/pipeline you intend to replicate (from which crowdsourcing paper). As a reminder, you should [pick a crowdsourcing paper here](https://docs.google.com/spreadsheets/d/1nIoU04CulTH128-r6rtykhuqNdd37UJXShw2J19IEdE/edit?usp=sharing). The spreadsheet also points to example tasks in the crowdsourcing papers; However, you DON'T have to stick to the paper-provided input/output. Please feel free to come up with your own tasks as long as they seem suitable for the paper/pipeline you are replicating.\n",
    " \n",
    "\n",
    "**EDIT THIS PART TO PROVIDE AN OVERVIEW OF YOUR ATTEMPTS**\n",
    "\n",
    "- **Task Description**: (description of your testing task.)\n",
    "- **Example Input/output**: Write >=3 input-output pairs of your task. You should test your strategy on all the three examples.\n",
    "    ```\n",
    "    Input: [INPUT EXAMPLE]\n",
    "    Output: [OUTPUT EXAMPLE]\n",
    "    \n",
    "    Input: [INPUT EXAMPLE]\n",
    "    Output: [OUTPUT EXAMPLE]\n",
    "    \n",
    "    Input: [INPUT EXAMPLE]\n",
    "    Output: [OUTPUT EXAMPLE]\n",
    "    ```\n",
    "- **Workflow prompting strategy**: Describe your designed pipeline.\n",
    "- **Crowdsourcing paper**: [PAPER TITLE & URL](paper_url) -- where the pipelining strategy comes from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ce2af",
   "metadata": {},
   "source": [
    "## Coding: Use this part to do your prompting.\n",
    "\n",
    "**Please use `text-davinci-003` when you generate your final model outputs.** `text-davinci-003` is effectively InstructGPT, and it can do any language task with better quality, longer output, and consistent instruction-following than other versions of GPT-3 ([as discussed in this page](https://platform.openai.com/docs/models/overview)). Using the latest model can give you a better idea on what these models are (not) capable of.\n",
    "\n",
    "Tips for prompting:\n",
    "- [OpenAI playground](https://beta.openai.com/playground) offers more interactive prompting experiments.\n",
    "- Read the [API documentation](https://beta.openai.com/docs/api-reference/completions?lang=python) to use the right parameters (e.g., `temperature`, `max_length`).\n",
    "- Read the [tutorial doc](https://beta.openai.com/docs/introduction) to get a general sense of GPT-3.\n",
    "- Read [OpenAI examples](https://beta.openai.com/examples) to get a sense of what GPT-3 can do.\n",
    "\n",
    "Tips for saving credits:\n",
    "\n",
    "- You can use a cheaper model for tweaking your prompts (see [pricing](https://openai.com/api/pricing/)) before generating the final responses using the most capable model `text-davinci-003`. However, be careful that sometimes a prompt that seems to not work for any other models may works for `text-davinci-003`.\n",
    "- [AI21](https://www.ai21.com/studio) provides a model similar to GPT-3 / API service similar to OpenAI, and it involves more free credits for you to try. If you choose to use this, remember to also get its API key and set up the credential.\n",
    "- Play with [ChatGPT](https://chat.openai.com/chat) which is a free and similarly capable model. It uses a dialog interface (vs. InstructGPT / `text-davinci-003` uses text completion interface), so naturally your way of interacting with the model may change a bit (e.g., you will ask questions there but use incomplete sentences here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb6d7c",
   "metadata": {},
   "source": [
    "## Baseline prompting\n",
    "\n",
    "Use this section to do a one-step prompting for your selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42418f",
   "metadata": {},
   "source": [
    "## Crowdsourcing-Pipeline-inspired prompting\n",
    "\n",
    "Use this section to your selected pipeline prompting for your task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1a375",
   "metadata": {},
   "source": [
    "# Writeup 1: Report & Reflection\n",
    "\n",
    "Fill in the following three sections by reflecting on your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89544ac",
   "metadata": {},
   "source": [
    "## Report the result\n",
    "\n",
    "For all the inputs you tried, summarized the input, baseline output, pipeline output, which output you like and why. To answer \"why\", you should first think of some criteria you want to use for evaluating the output:\n",
    "\n",
    "### Important criteria:\n",
    "1. \n",
    "\n",
    "### Inputs and outputs:\n",
    "\n",
    "\n",
    "- **Input**:\n",
    "- **Baseline output**:\n",
    "- **Pipeline output**:\n",
    "- **Which output you like and why**:\n",
    "\n",
    "---\n",
    "\n",
    "- **Input**:\n",
    "- **Baseline output**:\n",
    "- **Pipeline output**:\n",
    "- **Which output you like and why**:\n",
    "\n",
    "---\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be490103",
   "metadata": {},
   "source": [
    "## Reflect on prompting effectiveness\n",
    "\n",
    "Write some paragraphs to describe: Did you find the pipeline prompting workflow effective? Why or Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2595b22b",
   "metadata": {},
   "source": [
    "## Envision possible improvements\n",
    "\n",
    "Write some paragraphs to describe: What are some possible ways to further improve the pipeline or prompt design?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cacc9a",
   "metadata": {},
   "source": [
    "# Writeup 2 (Optional): InstructGPT vs. ChatGPT\n",
    "\n",
    "If you also tried to use the [ChatGPT](https://chat.openai.com/chat) interface to complete your task, you might have thoughts on these following two questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee675e",
   "metadata": {},
   "source": [
    "## Chat interface vs. complete-the-sentence interface\n",
    "Did your way of prompting change based on the interaction interface? What do you think are some pros and cons for the chat interface (you used in ChatGPT), and the complete-the-sentence interface (you used in this notebook)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5f2e8",
   "metadata": {},
   "source": [
    "## Qualitative reflection on outputs\n",
    "Provide some examples of your ChatGPT output. Did you notice any differences?\n",
    "\n",
    "\n",
    "- **Input**:\n",
    "- **InstructGPT output**:\n",
    "- **ChatGPT output**:\n",
    "- **Which output you like and why**:\n",
    "\n",
    "---\n",
    "\n",
    "- **Input**:\n",
    "- **InstructGPT output**:\n",
    "- **ChatGPT output**:\n",
    "- **Which output you like and why**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de50d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
